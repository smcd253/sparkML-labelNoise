# Prepare training and test data.

# df_train_pro = pd.read_table(f'{os.getcwd()}/train_pro.tsv', 
#                            delim_whitespace=True,
#                            low_memory=False,).T
# df_test_pro = pd.read_table(f'{os.getcwd()}/test_pro.tsv', 
#                            delim_whitespace=True,
#                            low_memory=False,).T
# df_train_cli = pd.read_csv(f'{os.getcwd()}/train_cli.tsv', 
#                            delim_whitespace=True,
#                            low_memory=False,)
# df_test_cli = pd.read_csv(f'{os.getcwd()}/test_cli.tsv', 
#                            delim_whitespace=True,
#                            low_memory=False,)
# df_train_mislabel = pd.read_csv(f'{os.getcwd()}/sum_tab_1.csv', 
#                            low_memory=False,)

data = spark.read.format("libsvm")\
    .load("/home/ec2-user/project/sparkML-labelNoise/spencer/sum_tab_1.data")

# df_train_pro = spark.read.format("libsvm")\
#     .load("/home/ec2-user/project/sparkML-labelNoise/spencer/sum_tab_1.data")

# df_test_pro = spark.read.format("libsvm")\
#     .load("/home/ec2-user/project/sparkML-labelNoise/spencer/sum_tab_1.data")

# USE train_rna_combined and train_pro_combined
# filter out all samples with mismatch = 1

# train/test based on gender as y, x as features
# train/test based on msi as y, x as features

train, test = data.randomSplit([0.9, 0.1], seed=12345)

lr = LinearRegression(maxIter=10) # change to random forrest

rf = RandomForrest()

# We use a ParamGridBuilder to construct a grid of parameters to search over.
# TrainValidationSplit will try all combinations of values and determine best model using
# the evaluator.
paramGrid = ParamGridBuilder()\
    .addGrid(lr.regParam, [0.1, 0.01]) \
    .addGrid(lr.fitIntercept, [False, True])\
    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\
    .build()

# In this case the estimator is simply the linear regression.
# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.
# change num extimators to 1000
# NEED TO MAKE SURE THE SURE EACH SPLIT HAS SIMILAR DISTRIBUTIONS
tvs = TrainValidationSplit(estimator=lr,
                           estimatorParamMaps=paramGrid,
                           evaluator=RegressionEvaluator(),
                           # 80% of the data will be used for training, 20% for validation.
                           trainRatio=0.8)

# Run TrainValidationSplit, and choose the best set of parameters.
model = tvs.fit(df_train_pro)

# Make predictions on test data. model is the model with combination of parameters
# that performed best.
model.transform(test)\
    .select("features", "label", "prediction")\
    .show()